{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46e56735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image: non-ads\\1pixel.gif. Skipping...\n",
      "Error loading image: non-ads\\m. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shivy\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 532ms/step - accuracy: 0.8125 - loss: 0.7711 - val_accuracy: 0.8889 - val_loss: 0.4724\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 423ms/step - accuracy: 0.8543 - loss: 0.4621 - val_accuracy: 0.8889 - val_loss: 0.2802\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 428ms/step - accuracy: 0.8960 - loss: 0.3439 - val_accuracy: 0.9722 - val_loss: 0.2076\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 421ms/step - accuracy: 0.9271 - loss: 0.2824 - val_accuracy: 0.9444 - val_loss: 0.2055\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 417ms/step - accuracy: 0.9213 - loss: 0.2862 - val_accuracy: 0.9722 - val_loss: 0.1680\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 421ms/step - accuracy: 0.9635 - loss: 0.1495 - val_accuracy: 0.9722 - val_loss: 0.1632\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 421ms/step - accuracy: 0.9620 - loss: 0.1151 - val_accuracy: 0.9722 - val_loss: 0.1339\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 450ms/step - accuracy: 0.9734 - loss: 0.1051 - val_accuracy: 0.9722 - val_loss: 0.1499\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 429ms/step - accuracy: 0.9831 - loss: 0.0517 - val_accuracy: 0.9722 - val_loss: 0.1218\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 430ms/step - accuracy: 0.9964 - loss: 0.0397 - val_accuracy: 0.9722 - val_loss: 0.1745\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9606 - loss: 0.1993\n",
      "Test Accuracy: 0.95652174949646\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ad       1.00      0.67      0.80         6\n",
      "      non-ad       0.95      1.00      0.98        40\n",
      "\n",
      "    accuracy                           0.96        46\n",
      "   macro avg       0.98      0.83      0.89        46\n",
      "weighted avg       0.96      0.96      0.95        46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import base64\n",
    "\n",
    "# Function to download images\n",
    "def download_image(url, folder):\n",
    "    if url.startswith('data:image'):\n",
    "        # Decode Base64 image\n",
    "        base64_str = url.split(';base64,')[-1]\n",
    "        image_data = base64.b64decode(base64_str)\n",
    "        \n",
    "        # Save the image to a file\n",
    "        filename = os.path.join(folder, f'image_{len(os.listdir(folder))}.jpg')\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(image_data)\n",
    "    else:\n",
    "        # For regular image URLs\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            filename = os.path.join(folder, url.split(\"/\")[-1].split(\"?\")[0])\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "# Create directories for saving images\n",
    "os.makedirs('ads', exist_ok=True)\n",
    "os.makedirs('non-ads', exist_ok=True)\n",
    "\n",
    "# Scraping ad images from Google Display Network Gallery\n",
    "ad_url = 'https://www.google.com/ads/gallery/'\n",
    "response = requests.get(ad_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "images = soup.find_all('img')\n",
    "for img in images:\n",
    "    img_url = img['src']\n",
    "    download_image(img_url, 'ads')\n",
    "\n",
    "# Scraping non-ad images from Unsplash\n",
    "non_ad_url = 'https://unsplash.com/'\n",
    "response = requests.get(non_ad_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "images = soup.find_all('img')\n",
    "for img in images:\n",
    "    img_url = img['src']\n",
    "    download_image(img_url, 'non-ads')\n",
    "\n",
    "# Create dataset\n",
    "ad_files = os.listdir('ads')\n",
    "non_ad_files = os.listdir('non-ads')\n",
    "\n",
    "ad_data = [{'filename': os.path.join('ads', filename), 'label': 'ad'} for filename in ad_files]\n",
    "non_ad_data = [{'filename': os.path.join('non-ads', filename), 'label': 'non-ad'} for filename in non_ad_files]\n",
    "\n",
    "df = pd.DataFrame(ad_data + non_ad_data)\n",
    "df.to_csv('dataset.csv', index=False)\n",
    "\n",
    "# Data preprocessing\n",
    "X = []\n",
    "y = []\n",
    "for index, row in df.iterrows():\n",
    "    img = cv2.imread(row['filename'])\n",
    "    if img is not None:  # Check if the image is loaded successfully\n",
    "        img = cv2.resize(img, (224, 224))  # Resize images to a fixed size\n",
    "        X.append(img)\n",
    "        y.append(row['label'])\n",
    "    else:\n",
    "        print(f\"Error loading image: {row['filename']}. Skipping...\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array(X) / 255.0  # Normalize pixel values\n",
    "y = np.array(y)\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['ad', 'non-ad']\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(class_labels)\n",
    "y_encoded = label_encoder.transform(y)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model building\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "\n",
    "# Generate classification report\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "# Map numerical labels back to original class names\n",
    "class_names = label_encoder.inverse_transform([0, 1])\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fcc23c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
